{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "import numpy as np\n",
    "from after_image.feature_extractor import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../69897e94e24170c0_UQIOT2022_A7369/data/\"\n",
    "\n",
    "common_attack_types = [\n",
    "    \"ACK_Flooding\",\n",
    "    \"ARP_Spoofing\",\n",
    "    \"Port_Scanning\",\n",
    "    \"Service_Detection\",\n",
    "    \"SYN_Flooding\",\n",
    "    \"UDP_Flooding\"\n",
    "]\n",
    "\n",
    "device_attacks = {\n",
    "    \"Cam_1\": common_attack_types,\n",
    "    \"Google-Nest-Mini_1\": common_attack_types,\n",
    "    \"Lenovo_Bulb_1\": common_attack_types ,\n",
    "    \"Raspberry_Pi_telnet\": common_attack_types + [\"HTTP_Flooding\", \"Telnet-brute_Force\"],\n",
    "    \"Smart_Clock_1\": common_attack_types,\n",
    "    \"Smartphone_1\": common_attack_types,\n",
    "    \"Smartphone_2\": common_attack_types,\n",
    "    \"SmartTV\": common_attack_types\n",
    "}\n",
    "\n",
    "save_path = \"./kitsune_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_kitsune(pcap_file, output_file_name, count=float('Inf'), parse_type=\"scapy\"):\n",
    "    \"\"\"\n",
    "    Obtains features from a pcap file using the Kitsune feature extractor.\n",
    "\n",
    "    Parameters:\n",
    "        pcap_file (string): Path to pcap file.\n",
    "        output_file_name (string): Output path of the feature file.\n",
    "        count (int): Number of packets to process. Defaults to float('Inf').\n",
    "        parse_type (string): Either scapy or tshark. Defaults to \"scapy\".\n",
    "\n",
    "    File I/O:\n",
    "        Resulting file is written to output_file_name.\n",
    "    \"\"\"\n",
    "    print(\"parsing:\", pcap_file)\n",
    "\n",
    "    feature_extractor = FE(pcap_file, parse_type=parse_type)\n",
    "    headers = feature_extractor.nstat.getNetStatHeaders()\n",
    "    npy_array = []\n",
    "\n",
    "    output_file = open(output_file_name, \"w\")\n",
    "    np.savetxt(output_file, [headers], fmt=\"%s\", delimiter=\",\")\n",
    "\n",
    "    skipped = 0\n",
    "    written = 0\n",
    "    t = tqdm(total=count)\n",
    "    pkt_index = 0\n",
    "    while pkt_index < count:\n",
    "        try:\n",
    "            if parse_type == \"scapy\":\n",
    "                traffic_data, _ = feature_extractor.get_next_vector()\n",
    "            else:\n",
    "                traffic_data = feature_extractor.get_next_vector()\n",
    "        except EOFError as e:\n",
    "            print(\"EOF Reached\")\n",
    "            print(e)\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(\"EOF Reached\")\n",
    "            print(e)\n",
    "            break\n",
    "        except StopIteration as e:\n",
    "            print(e)\n",
    "            print(\"EOF Reached\")\n",
    "            break\n",
    "\n",
    "        pkt_index += 1\n",
    "        t.update(1)\n",
    "        if traffic_data == []:\n",
    "            np.savetxt(output_file, np.full(\n",
    "                features.shape, -1), delimiter=\",\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "        features = feature_extractor.nstat.updateGetStats(*traffic_data)\n",
    "\n",
    "        if np.isnan(features).any():\n",
    "            print(features)\n",
    "            break\n",
    "        \n",
    "        npy_array.append(features)\n",
    "        features = np.expand_dims(features, axis=0)\n",
    "        np.savetxt(output_file, features, delimiter=\",\", fmt=\"%s\")\n",
    "        written += 1\n",
    "    t.close()\n",
    "    np.save(output_file_name[:-3] + \"npy\", np.asarray(npy_array))\n",
    "    output_file.close()\n",
    "    print(\"skipped:\", skipped)\n",
    "    print(\"written:\", written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for attacks on devices\n",
    "for device in device_attacks.keys():\n",
    "    for attack in device_attacks[device]:\n",
    "        in_path = dataset_path + \"attack_samples/\" + device + \"/\" + attack + \"_\" + device + \".pcap\"\n",
    "        out_path = save_path + device + \"/\" + attack + \".csv\"\n",
    "        parse_kitsune(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract host discovery traffic samples\n",
    "in_path = dataset_path + \"attack_samples/Host_Discovery\" + \".pcap\"\n",
    "out_path = save_path + \"Host_Discovery\" + \".csv\"\n",
    "parse_kitsune(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract benign samples\n",
    "in_path = dataset_path + \"benign_samples/whole_week.pcap\"\n",
    "out_path = save_path + \"benign\" + \".csv\"\n",
    "parse_kitsune(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
